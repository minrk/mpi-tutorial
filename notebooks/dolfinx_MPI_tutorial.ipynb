{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d29c16a2",
   "metadata": {},
   "source": [
    "# Parallel Computations with Dolfinx using MPI\n",
    "\n",
    "The aim of this tutorial is to show how variational problems can be solved with Python using Dolfinx running in parallel. The Message Passing Interface (MPI) standard will be used to carry out parallel computations. We will use the mpi4py package to interface MPI in Python.\n",
    "\n",
    "First, we will look at some basic examples of MPI usage.\n",
    "\n",
    "Next, we will cover how to define finite element function spaces and functions on several processes.\n",
    "\n",
    "Furthermore, creating and distributing a finite element mesh in parallel will be demonstrated.\n",
    "\n",
    "Finally, the elements of the tutorial are combined to show how the variational problem related to a partial differential equation can be solved in parallel.\n",
    "\n",
    "This tutorial is inspired by and based on https://newfrac.gitlab.io/newfrac-fenicsx-training/05-dolfinx-parallel/dolfinx-parallel.html and https://jsdokken.com/dolfinx_docs/meshes.html.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6f541fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Parallel programming imports\n",
    "import ipyparallel as ipp\n",
    "\n",
    "from mpi4py import MPI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcfffafd-83ee-4d09-a2db-303070669b0a",
   "metadata": {},
   "source": [
    "## Setting up a cluster\n",
    "ipyparallel is used to set up a local cluster consisting of 2 processors. To run Jupyter Notebook cells in parallel, we use %%px cell magic. To learn more about this, see the first parts of the MPI tutorial ([Introduction to MPI](./intro-mpi/intro-mpi.ipynb)) as well as https://ipyparallel.readthedocs.io/en/latest/tutorial/magics.html#px-cell-magic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c140fdc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting 2 engines with <class 'ipyparallel.cluster.launcher.MPIEngineSetLauncher'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/fenicsx/lib/python3.10/site-packages/ipyparallel/util.py:210: RuntimeWarning: IPython could not determine IPs for Halvors-MacBook-Pro-2.local: [Errno 1] Unknown host\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af2a1e19d5c4449e9b1ebf4c34c4609b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?engine/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cluster = ipp.Cluster(engines = \"mpi\", n = 2)\n",
    "rc = cluster.start_and_connect_sync()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00910f35-9df6-4f43-a7a2-5065b6f1b869",
   "metadata": {},
   "source": [
    "## MPI communication in DOLFINx\n",
    "When constructing a mesh in DOLFINx, the type of communicator must be specified. The mesh is partitioned by distributing the nodes of the mesh over different processes.\n",
    "\n",
    "A parameter 'ghost_mode' must be specified. This determines how shared nodes are distributed as ghost nodes between the processes, i.e. which nodes are owned by the local processes and which nodes are ghost nodes that belong to the neighboring processes. We will used the 'shared_facet' option, where facet nodes are shared after mesh partitioning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "09fec8d4-2f90-4c5c-89fe-b32e8c78cdf8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%px\n",
    "import dolfinx as dfx\n",
    "import ufl\n",
    "\n",
    "comm = MPI.COMM_WORLD # MPI communicator\n",
    "\n",
    "# Define a function used to print stuff with the processor rank number in front\n",
    "def mpi_print(s):\n",
    "    print(f\"Rank {comm.rank}: {s}\")\n",
    "\n",
    "Nx, Ny = 2, 2 # Mesh size\n",
    "\n",
    "# Create a unit square mesh\n",
    "mesh = dfx.mesh.create_unit_square(comm, Nx, Ny, ghost_mode = dfx.cpp.mesh.GhostMode.shared_facet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d4d69d-bcc5-47a1-9560-f24b4c02d535",
   "metadata": {},
   "source": [
    "The connectivity mapping between cells, facets and vertices of the mesh must be created. If the problem at hand does not require e.g. the mapping between cells and facets, one can omit creating the respective connectivity map to save computation time. Let's create the mapping between cells (for the unit square these are of dimension 2) and facets (dimension 1) and print them to see how they are distributed over the two processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d77bdc4-d4c2-4326-b2ca-ed9b43272229",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[stdout:1] Cell (dim = 2) to facet (dim = 1) connectivity:\n",
       "Rank 1: <AdjacencyList> with 6 nodes\n",
       "  0: [0 8 7 ]\n",
       "  1: [2 1 0 ]\n",
       "  2: [4 1 3 ]\n",
       "  3: [6 5 2 ]\n",
       "  4: [9 8 10 ]\n",
       "  5: [12 5 11 ]\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[stdout:0] Cell (dim = 2) to facet (dim = 1) connectivity:\n",
       "Rank 0: <AdjacencyList> with 6 nodes\n",
       "  0: [5 4 0 ]\n",
       "  1: [6 1 5 ]\n",
       "  2: [3 1 2 ]\n",
       "  3: [7 8 6 ]\n",
       "  4: [10 4 9 ]\n",
       "  5: [12 8 11 ]\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%px\n",
    "mesh.topology.create_connectivity(2, 1)\n",
    "print(\"Cell (dim = 2) to facet (dim = 1) connectivity:\")\n",
    "mpi_print(mesh.topology.connectivity(2, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f89363-c8f9-4f02-a634-d9d69b087565",
   "metadata": {},
   "source": [
    "The ghost nodes for each processor rank is stored in the index map of the mesh topology:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8d8e71e5-ba72-4aa3-83df-24692e01cab6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[stdout:0] Rank 0: Ghost cells (global numbering): [4 7]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[stdout:1] Rank 1: Ghost cells (global numbering): [0 3]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%px\n",
    "mpi_print(f\"Ghost cells (global numbering): {mesh.topology.index_map(2).ghosts}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90adf486-bcba-4259-b93f-77080d9cb6cc",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Dolfinx function spaces\n",
    "The degrees of freedom of a finite element function space in dolfinx is distributed over the nodes of the mesh. To illustrate, we create a function space with 1st order Lagrange elements and print the global and local sizes of the dofmap, as well as the ghost nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ca8b487d-09e4-45c4-bd90-784f511f74d3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[stdout:1] Rank 1: Global dofmap size: 9\n",
       "Rank 1: Local dofmap size: 5\n",
       "Rank 1: Ghosts: [0 1 2]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[stdout:0] Rank 0: Global dofmap size: 9\n",
       "Rank 0: Local dofmap size: 4\n",
       "Rank 0: Ghosts: [5 8 4 6]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%px\n",
    "V = dfx.fem.FunctionSpace(mesh, (\"Lagrange\", 1))\n",
    "\n",
    "mpi_print(f\"Global dofmap size: {V.dofmap.index_map.size_global}\")\n",
    "mpi_print(f\"Local dofmap size: {V.dofmap.index_map.size_local}\")\n",
    "mpi_print(f\"Ghosts: {V.dofmap.index_map.ghosts}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a6141a-5fb2-44c8-a8c9-2f1b035039e4",
   "metadata": {},
   "source": [
    "## Dolfinx functions\n",
    "The degrees of freedom of a dolfinx function is distributed over the nodes of the mesh in the same way as function spaces, as the functions created from a function space inherit the dofmap of the space that they live in. We create a function from the previously defined space $V$ and print the size of the array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8fa7a806-d9ee-405c-965e-6fec591e028c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[stdout:1] Rank 1: Local size of array: 5\n",
       "Rank 1: Global size of array: 9\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[stdout:0] Rank 0: Local size of array: 4\n",
       "Rank 0: Global size of array: 9\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%px\n",
    "u = dfx.fem.Function(V)\n",
    "mpi_print(f\"Local size of array: {u.x.map.size_local}\")\n",
    "mpi_print(f\"Global size of array: {u.x.map.size_global}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a3adac5-7d4b-48f8-9254-16ab700310db",
   "metadata": {},
   "source": [
    "Since we have a scalar function, the size of the array of the function values is the same as the number of nodes in the mesh. If we e.g. had a two-dimensional vector function, the size of the array would be double the amount of mesh nodes.\n",
    "\n",
    "We can also print the ghost nodes and the rank of the processor owning the ghost nodes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0699659e-9d73-48d2-a0be-36f3288dedea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[stdout:0] Rank 0: Ghosts: [5 8 4 6]\n",
       "Rank 0: Ghost owners: [1 1 1 1]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[stdout:1] Rank 1: Ghosts: [0 1 2]\n",
       "Rank 1: Ghost owners: [0 0 0]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%px\n",
    "mpi_print(f\"Ghosts: {u.x.map.ghosts}\")\n",
    "mpi_print(f\"Ghost owners: {u.x.map.owners}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f671131-50fe-4aeb-bb00-1454fd3de745",
   "metadata": {},
   "source": [
    "## Assembling scalars, vectors, matrices in parallel\n",
    "To solve continuous problems numerically, we have to assemble a linear system of equations arising from discretization. Assembling scalars, vectors and matrices in dolfinx has to be carried out carefully when using several processes. We have to make sure that the processors communicate changes in values of overlapping nodes. We start by creating trial and test functions $u$ and $v$ from our function space $V$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "230c3bb9-3b52-4450-870a-f2d8541b6457",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%px\n",
    "\n",
    "# Trial and test functions\n",
    "u = ufl.TrialFunction(V)\n",
    "v = ufl.TestFunction (V)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f91f8a76-994c-4c16-9c67-21f9790b73d0",
   "metadata": {},
   "source": [
    "Let us consider a linear form\n",
    "$$L(v) = \\int_{\\Omega}f v dx $$\n",
    "where $v$ is a test function, $\\Omega$ is the domain that we have discretized with our mesh and $f$ is a scalar-valued function. The test function is discretized with 1st order continuous Lagrange elements, and to assemble it as a vector we can run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3f8dbf3b-12ac-428e-a078-906277074abc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%px\n",
    "\n",
    "import ufl\n",
    "\n",
    "# UFL form of right-hand side\n",
    "L = ufl.inner(1.0, v) * ufl.dx\n",
    "L = dfx.fem.form(L)\n",
    "\n",
    "# Assemble UFL form into a vector\n",
    "_b = dfx.fem.Function(V)\n",
    "dfx.fem.petsc.assemble_vector(_b.vector, L)\n",
    "_b.x.scatter_forward()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f786bfb9-109d-489e-8dba-5bac4638e465",
   "metadata": {},
   "source": [
    "Now, after assembling, it is important to distribute the node values from the different processes. After the initial assembly, our vector holds the values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2a4ebf6e-f31e-46b5-8ee6-e168df63c3f8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[stdout:1] Prior to communication\n",
       "Rank 1: [0.125      0.125      0.125      0.04166667 0.04166667 0.04166667\n",
       " 0.125      0.125     ]\n",
       "After ADD/REVERSE update\n",
       "Rank: 1: [0.25       0.25       0.25       0.04166667 0.08333333 0.04166667\n",
       " 0.125      0.125     ]\n",
       "After INSERT/FORWARD update\n",
       "Rank: 1: [0.25       0.25       0.25       0.04166667 0.08333333 0.08333333\n",
       " 0.25       0.25      ]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[stdout:0] Prior to communication\n",
       "Rank 0: [0.04166667 0.125      0.125      0.04166667 0.125      0.04166667\n",
       " 0.125      0.125     ]\n",
       "After ADD/REVERSE update\n",
       "Rank: 0: [0.08333333 0.25       0.25       0.04166667 0.125      0.04166667\n",
       " 0.125      0.125     ]\n",
       "After INSERT/FORWARD update\n",
       "Rank: 0: [0.08333333 0.25       0.25       0.04166667 0.25       0.08333333\n",
       " 0.25       0.25      ]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%px\n",
    "# Print the size of the index map and the number of ghost nodes\n",
    "#print(V.dofmap.index_map.size_local*V.dofmap.index_map_bs, V.dofmap.index_map.num_ghosts*V.dofmap.index_map_bs)\n",
    "print(\"Prior to communication\")\n",
    "mpi_print(_b.x.array)  \n",
    "\n",
    "# Add values from ghost regions and accumulate them on the owning process\n",
    "_b.x.scatter_reverse(dfx.la.ScatterMode.add)\n",
    "\n",
    "#_b.vector.ghostUpdate(addv = PETSc.InsertMode.ADD, mode = PETSc.ScatterMode.REVERSE)\n",
    "\n",
    "print(\"After ADD/REVERSE update\")\n",
    "print(f\"Rank: {comm.rank}: {_b.x.array}\")   \n",
    "\n",
    "# Ghost points still not updated, so their values are inconsistent\n",
    "# Get value from owning process and update the ghosts\n",
    "_b.x.scatter_forward()\n",
    "#_b.ghostUpdate(addv = PETSc.InsertMode.INSERT, mode = PETSc.ScatterMode.FORWARD)\n",
    "\n",
    "print(\"After INSERT/FORWARD update\")\n",
    "print(f\"Rank: {comm.rank}: {_b.x.array}\")   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b150a3dd-a283-4230-b9a2-f6309836ecd4",
   "metadata": {},
   "source": [
    "The values from the ghost nodes can be accumulated on the owning process by running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e8e1b2fe-944b-4944-970d-908ec9ab068b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[stdout:1] After ADD/REVERSE update\n",
       "Rank 1: [0.5        0.5        0.5        0.04166667 0.16666667 0.08333333\n",
       " 0.25       0.25      ]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[stdout:0] After ADD/REVERSE update\n",
       "Rank 0: [0.16666667 0.5        0.5        0.04166667 0.25       0.08333333\n",
       " 0.25       0.25      ]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%px\n",
    "\n",
    "# Add values from ghost regions and accumulate them on the owning process\n",
    "_b.x.scatter_reverse(dfx.la.ScatterMode.add)\n",
    "\n",
    "print(\"After ADD/REVERSE update\")\n",
    "mpi_print(_b.x.array)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef61475c-bd55-4852-9182-40eaeb27db99",
   "metadata": {},
   "source": [
    "The ghost nodes are still not updated, and now we must distribute the values from the owning process to the ghost nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6f7059a8-e73c-49d7-8b0c-417f80a8f065",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[stdout:0] After INSERT/FORWARD update\n",
       "Rank 0: [0.16666667 0.5        0.5        0.04166667 0.5        0.16666667\n",
       " 0.5        0.5       ]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[stdout:1] After INSERT/FORWARD update\n",
       "Rank 1: [0.5        0.5        0.5        0.04166667 0.16666667 0.16666667\n",
       " 0.5        0.5       ]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%px\n",
    "\n",
    "# Get value from owning process and update the ghosts\n",
    "_b.x.scatter_forward()\n",
    "\n",
    "print(\"After INSERT/FORWARD update\")\n",
    "mpi_print(_b.x.array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d082121-d6c1-4e77-8e6d-58bfd2817fe9",
   "metadata": {},
   "source": [
    "## Putting it all together: Solving a variational problem\n",
    "We will consider solving a Poisson problem on the unit square domain, denoted $\\Omega$. The strong form of the problem is: determine $u$ such that\n",
    "\\begin{align}\n",
    "    -\\nabla^2 u &= f \\quad \\mathrm{in} \\ \\Omega, \\\\\n",
    "    u &= g \\quad \\mathrm{on} \\ \\partial\\Omega,\n",
    "\\end{align}\n",
    "where $\\partial\\Omega$ is the boundary of the domain. The weak form of the problem is derived by multiplying the PDE with a test function $v$, integrating over the domain and applying integration by parts. This yields\n",
    "\n",
    "$$\\int_{\\Omega} \\nabla u \\cdot \\nabla v dx = \\int_{\\Omega}f v dx$$\n",
    "\n",
    "where the boundary integral vanishes because $v = 0$ on the boundary due to the Dirichlet boundary condition. For simplicity we set $g = 0$.\n",
    "\n",
    "The finite element problem can now be defined as: find $u_h \\in V_h$ such that\n",
    "$$a(u_h, v_h) = L(v_h), \\forall \\ v_h \\in V_h,$$\n",
    "where $V_h$ is the finite element space and\n",
    "$$a(u, v) = \\int_{\\Omega} \\nabla u \\cdot \\nabla v dx$$\n",
    "and\n",
    "$$L(v) = \\int_{\\Omega}f v dx.$$\n",
    "The subscript $h$ emphasizes that the variables are defined on a discrete mesh.\n",
    "\n",
    "PETSc is the linear algebra backend used for solving the linear system of equations that defines the weak form. For more information on the Krylov solver used here and its options, see: https://petsc.org/release/.\n",
    "\n",
    "To visualize the solution, we use pyvista (https://docs.pyvista.org/). For a simple introduction to defining and solving variational problems with FEniCSx, see https://jsdokken.com/dolfinx-tutorial/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1bd0b245-b1e4-4d1f-9e11-a12e652a4bcb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[stdout:1] 5 1\n",
       "Prior to communication\n",
       "Rank: 1: [0.     0.0625 0.     0.     0.     0.    ]\n",
       "After scatter_forward update\n",
       "Rank: 1: [0.     0.0625 0.     0.     0.     0.    ]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[stdout:0] 4 2\n",
       "Prior to communication\n",
       "Rank: 0: [0. 0. 0. 0. 0. 0.]\n",
       "After scatter_forward update\n",
       "Rank: 0: [0.     0.     0.     0.     0.0625 0.    ]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e2971e92d294c99adf19eaa643ce5cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "%px:   0%|          | 0/2 [00:00<?, ?tasks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[output:0]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3b71c7424ff469f8e358c2e057eaea4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ViewInteractiveWidget(height=768, layout=Layout(height='auto', width='100%'), width=1024)"
      ]
     },
     "metadata": {
      "engine": 0
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[output:1]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce77b81e024c45eeaf48e130d9eb4ddd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ViewInteractiveWidget(height=768, layout=Layout(height='auto', width='100%'), width=1024)"
      ]
     },
     "metadata": {
      "engine": 1
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%px\n",
    "\n",
    "import ufl\n",
    "from petsc4py import PETSc\n",
    "import pyvista as pv\n",
    "\n",
    "comm = MPI.COMM_WORLD # MPI communicator\n",
    "\n",
    "Nx, Ny = 2, 2 # Mesh size\n",
    "\n",
    "# Create a unit square mesh\n",
    "mesh = dfx.mesh.create_unit_square(comm, Nx, Ny, ghost_mode = dfx.cpp.mesh.GhostMode.none)\n",
    "mesh.topology.create_entities(mesh.topology.dim - 1)\n",
    "mesh.topology.create_connectivity(mesh.topology.dim - 1, mesh.topology.dim)\n",
    "\n",
    "# Create a first-order Lagrange finite element space\n",
    "V = dfx.fem.FunctionSpace(mesh, (\"CG\", 1))\n",
    "\n",
    "# Trial and test functions\n",
    "u = ufl.TrialFunction(V)\n",
    "v = ufl.TestFunction (V)\n",
    "\n",
    "u_h = dfx.fem.Function(V) # Solution function\n",
    "\n",
    "f = dfx.fem.Function(V) # Source term\n",
    "f.x.set(1) # Set function value to 1\n",
    "\n",
    "\n",
    "# UFL form of the bilinear form\n",
    "a = ufl.inner(ufl.grad(u), ufl.grad(v)) * ufl.dx\n",
    "bilinear_form = dfx.fem.form(a)\n",
    "\n",
    "# UFL form of right-hand side\n",
    "L = f * v * ufl.dx\n",
    "linear_form = dfx.fem.form(L)\n",
    "\n",
    "# Boundary condition function\n",
    "g = dfx.fem.Function(V) # Dolfinx function, default function value = 0\n",
    "\n",
    "# Get the dofs of the boundary facets\n",
    "boundary_facets = dfx.mesh.exterior_facet_indices(mesh.topology)\n",
    "boundary_dofs   = dfx.fem.locate_dofs_topological(V, mesh.topology.dim - 1, boundary_facets)\n",
    "bc_g = dfx.fem.dirichletbc(g, boundary_dofs)\n",
    "\n",
    "bcs = [bc_g]\n",
    "\n",
    "# Assemble matrix from the bilinear form\n",
    "A = dfx.fem.petsc.assemble_matrix(bilinear_form, bcs = bcs)\n",
    "A.assemble()\n",
    "\n",
    "# Assemble UFL form into a vector\n",
    "_b = dfx.fem.Function(V) # Dolfinx function of right-hand side\n",
    "dfx.fem.petsc.assemble_vector(_b.vector, linear_form)\n",
    "dfx.fem.petsc.apply_lifting(_b.vector, [bilinear_form], bcs = [bcs])\n",
    "_b.x.scatter_reverse(dfx.la.ScatterMode.add)\n",
    "dfx.fem.petsc.set_bc(_b.vector, bcs = bcs)\n",
    "\n",
    "# Create a (direct) linear solver\n",
    "solver = PETSc.KSP().create(mesh.comm)\n",
    "solver.setOperators(A)\n",
    "solver.setType(\"preonly\")\n",
    "solver.getPC().setType(\"lu\")\n",
    "solver.getPC().setFactorSolverType(\"mumps\")\n",
    "\n",
    "# Solve the variational problem\n",
    "solver.solve(_b.vector, u_h.vector)\n",
    "\n",
    "# Print the size of the index map and the number of ghost nodes\n",
    "print(V.dofmap.index_map.size_local*V.dofmap.index_map_bs, V.dofmap.index_map.num_ghosts*V.dofmap.index_map_bs)\n",
    "\n",
    "print(\"Prior to communication\")\n",
    "print(f\"Rank: {comm.rank}: {u_h.x.array}\")   \n",
    "# Get value from owning process and update the ghosts\n",
    "u_h.x.scatter_forward()\n",
    "\n",
    "\n",
    "print(\"After scatter_forward update\")\n",
    "print(f\"Rank: {comm.rank}: {u_h.x.array}\")   \n",
    "\n",
    "# Visualize the solution\n",
    "topology, cell_types, x = dfx.plot.create_vtk_mesh(V)\n",
    "grid = pv.UnstructuredGrid(topology, cell_types, x)\n",
    "\n",
    "# Set output data\n",
    "grid.point_data[\"u\"] = u_h.x.array.real\n",
    "grid.set_active_scalars(\"u\")\n",
    "\n",
    "# Create a pyvista plotter object and plot the datagrid\n",
    "pl = pv.Plotter()\n",
    "pl.add_text(f\"Rank: {comm.rank}\", font_size = 12)\n",
    "pl.add_mesh(grid)\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f79ff1e2-ec92-40fa-8f32-3e87552bec82",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing hiding\n"
     ]
    }
   ],
   "source": [
    "# hide this cell\n",
    "print(\"testing hiding\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1cb52086-b014-4ab3-8e6d-09f71eb2bb99",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Stop the cluster\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mrc\u001b[49m\u001b[38;5;241m.\u001b[39mcluster\u001b[38;5;241m.\u001b[39mstop_cluster_sync()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'rc' is not defined"
     ]
    }
   ],
   "source": [
    "# Stop the cluster\n",
    "rc.cluster.stop_cluster_sync()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d00d30-187b-4e6d-801a-2fc663de7425",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
